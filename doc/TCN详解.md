# TCN详解及参考点
TCN并不指代一种模型，更像是一种框架如RNN、CNN、CNN-LSTM,可以进行模块化定制化开发
## 关键结构
1. Dilated Casual Conv-膨胀因果卷积
   * 卷积：卷积核滑动卷积数据
   * 膨胀：输入的数据存在间隔采样，具体实现看代码再解释
   * 因果：第i时刻数据只依赖i-1及之前的数据，不纯在对未来数据的读取，是一种严格的时间约束模型

2. WeightNorm-权重归一化
   对权重值进行归一化，通过重写网络权重来加速计算。
   * 通用性好：对网络权重归一化，不依赖样本数据量
   * 优于传统BN：BN局限于minibatch归一化统计量代替全局统计量，引入了梯度噪声，WN适于对数据噪声敏感的场景
   * 节省资源：WN没有额外参数，不占显存，计算效率高

3. ReLU
   * 加速网络收敛
   * 增减网络非线性，提高表达能力
   * 防止梯度消失
   * 使网络具有稀疏性

4. DropOut
   * 防止过拟合
   * 提高模型泛化性

5. 残差连接
   1*1卷积残差连接，保证输入输出维度一致

## TCN特征
* 感受野大，捕捉信息更多
* 相对于RNN，具备CNN的并行性
* 避免梯度消失和梯度爆炸
1. 跨时间步提取特征-膨胀卷积
   具体实现是在Conv1d的选项参数上设置dilations，以获得更大的感受野的同时减少计算量

2. 输入输出时间步不遗漏（no leakage）-RNN输入输出同长度
   TCN = 1-D FCN + Causal Convolutions
   这是原作者提出的TCN实现方案，兼具CNN的特性和RNN特性

### 1-D FCN
保证每一隐层输入输出时间长度一致

